{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phamquocanh149/IMDB_REVIEW/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSqlRbZ3ZMOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8bdfc6-af93-43b1-e2f4-b97116c98c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")\n",
        "train_data, test_data = imdb['train'], imdb['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ3Z4vY1aZJz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNTGOpeQaeJK"
      },
      "outputs": [],
      "source": [
        "train = pd.DataFrame(train_data)\n",
        "test = pd.DataFrame(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE4hqyuga5Oq",
        "outputId": "f05ea5d3-de5e-4616-fd33-72830bb49f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
            "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
            "2  If only to avoid making this type of film in t...      0\n",
            "3  This film was probably inspired by Godard's Ma...      0\n",
            "4  Oh, brother...after hearing about this ridicul...      0\n"
          ]
        }
      ],
      "source": [
        "print(train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BE8AFUPa7va",
        "outputId": "a717c92d-f2da-424a-a176-b139adf45fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MOh8ew4bW8Q",
        "outputId": "e589f4d1-02b6-4641-f22c-f12cb835f473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  I love sci-fi and am willing to put up with a ...      0\n",
            "1  Worth the entertainment value of a rental, esp...      0\n",
            "2  its a totally average film with a few semi-alr...      0\n",
            "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
            "4  First off let me say, If you haven't enjoyed a...      0\n"
          ]
        }
      ],
      "source": [
        "print(test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOzPijcCbY9v",
        "outputId": "1cc633ce-ef56-4ff6-e7ac-c98c2c07de0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXjqBy1GbdIv",
        "outputId": "70fe7203-552e-4b5d-8816-36f19c6270ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    12500\n",
            "1    12500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt_8WvzcbwwJ",
        "outputId": "39139032-cc02-40c0-dec7-409f754e68c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7968655cddc0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import spacy\n",
        "spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 torchtext==0.18.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trd2v2k24rfc",
        "outputId": "84dbfbbf-e04a-492e-b746-09cef0399e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0) (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjFGdJPdcJqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e21d9fa-42f6-4112-a0e3-1cc231ffd29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/transforms.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/functional.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.transforms import VocabTransform\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQg8LL3mb5Hw"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icdn9kgIl6am"
      },
      "outputs": [],
      "source": [
        "train['token'] = train['text'].apply(lambda x: tokenizer(x))\n",
        "test['token'] = test['text'].apply(lambda x: tokenizer(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu_zQ-O1mggV"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "X_train = train['token'].apply(lambda tokens: [token for token in tokens if token not in string.punctuation])\n",
        "X_test = test['token'].apply(lambda tokens: [token for token in tokens if token not in string.punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GI4kRopn9cm",
        "outputId": "d4ac3759-3b20-47ab-ca0f-e950367a1d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [I, rented, I, AM, CURIOUS, YELLOW, from, my, ...\n",
            "1    [I, Am, Curious, Yellow, is, a, risible, and, ...\n",
            "2    [If, only, to, avoid, making, this, type, of, ...\n",
            "3    [This, film, was, probably, inspired, by, Goda...\n",
            "4    [Oh, brother, ..., after, hearing, about, this...\n",
            "Name: token, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s64ytol3pcHu"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(lambda tokens: [token.lower() for token in tokens])\n",
        "X_test = X_test.apply(lambda tokens: [token.lower() for token in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-InpfmQm_fG"
      },
      "outputs": [],
      "source": [
        "vocab = build_vocab_from_iterator((token for token in X_train), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR9-v2XcxNme",
        "outputId": "1f9deca9-72fe-4d5a-d614-b19a2d999564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101135\n"
          ]
        }
      ],
      "source": [
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Nmt8xinuga",
        "outputId": "27ef2661-353a-498b-ec1e-19094b17b98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ],
      "source": [
        "print(type(test['label'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ85kXBCp5_S"
      },
      "outputs": [],
      "source": [
        "transform = VocabTransform(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xpVKyK6qSkS"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(transform)\n",
        "X_test = X_test.apply(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H53OJpCcqX5Z",
        "outputId": "de198d19-024a-4fb0-d859-d418c2e68ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [10, 1591, 10, 240, 2007, 4182, 38, 63, 373, 1...\n",
            "1        [10, 240, 2007, 4182, 7, 4, 19726, 3, 1951, 89...\n",
            "2        [49, 65, 6, 863, 231, 11, 549, 5, 21, 9, 2, 70...\n",
            "3        [11, 21, 15, 238, 1576, 35, 7436, 13, 81956, 7...\n",
            "4        [467, 558, 78, 104, 2218, 45, 11, 654, 21, 17,...\n",
            "                               ...                        \n",
            "24995    [4, 562, 33, 2, 61, 20, 160, 131, 32062, 16, 3...\n",
            "24996    [10, 120, 11, 19, 39, 59, 87, 167, 61, 10, 83,...\n",
            "24997    [11, 21, 3, 8, 13, 771, 3472, 16249, 1752, 28,...\n",
            "24998    [2, 2486, 5, 3472, 16249, 636, 118, 16, 4, 605...\n",
            "24999    [2, 66, 4678, 191, 3472, 16249, 37, 208, 142, ...\n",
            "Name: token, Length: 25000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdsrCyTNrEZ6"
      },
      "outputs": [],
      "source": [
        "def encode_sen(encode, pad_index, max_length = 300):\n",
        "  if len(encode) < max_length:\n",
        "    encode += [pad_index] * (max_length - len(encode))\n",
        "  else:\n",
        "    encode = encode[:max_length]\n",
        "  return encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdjSMIwiuTDB"
      },
      "outputs": [],
      "source": [
        "pad_index = vocab['<pad>']\n",
        "X_train = X_train.apply(lambda x: encode_sen(x, pad_index))\n",
        "X_test = X_test.apply(lambda x: encode_sen(x, pad_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kxiMmosuVwY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = torch.tensor(X, dtype=torch.long)\n",
        "    self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCuVR4CMwCzT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train = TextDataset(X_train, np.array(train['label'], dtype=int))\n",
        "test = TextDataset(X_test, np.array(test['label'], dtype=int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBWfw6STwLkl"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOI7vFvVwpet"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim,\n",
        "                                 batch_first=True)\n",
        "\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [batch size, sentence length]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "\n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB8h39-4wzil"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(14)\n",
        "model = RNN(input_dim=101135,\n",
        "            embedding_dim=32,\n",
        "            hidden_dim=32,\n",
        "            output_dim=2 # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_ii99ehx1zc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, optimizer, criterion, device, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)       # [batch_size, output_dim]\n",
        "\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # tính accuracy\n",
        "            acc = (predictions.argmax(1) == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_acc += acc\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        avg_acc = epoch_acc / len(train_loader)\n",
        "\n",
        "        # Evaluate trên validation set\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        val_loss, val_acc = evaluate(model, valid_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={avg_loss:.4f}, Train Acc={avg_acc:.4f} | \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8bYLmlty29f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            predictions = model(X_batch)\n",
        "\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            acc = (predictions.argmax(1) == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_acc += acc\n",
        "\n",
        "    avg_loss = epoch_loss / len(loader)\n",
        "    avg_acc = epoch_acc / len(loader)\n",
        "    return avg_loss, avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfRuSVH4y5iy",
        "outputId": "9884263d-a781-489d-8735-fb0192962443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.5674, Train Acc=0.6816 | Val Loss=0.5625, Val Acc=0.7638\n",
            "Epoch 2: Train Loss=0.3522, Train Acc=0.8624 | Val Loss=0.4894, Val Acc=0.8084\n",
            "Epoch 3: Train Loss=0.2055, Train Acc=0.9314 | Val Loss=0.4761, Val Acc=0.8251\n",
            "Epoch 4: Train Loss=0.1222, Train Acc=0.9647 | Val Loss=0.6332, Val Acc=0.8040\n",
            "Epoch 5: Train Loss=0.0765, Train Acc=0.9805 | Val Loss=0.6142, Val Acc=0.8234\n",
            "Epoch 6: Train Loss=0.0528, Train Acc=0.9874 | Val Loss=0.6723, Val Acc=0.8274\n",
            "Epoch 7: Train Loss=0.0379, Train Acc=0.9919 | Val Loss=0.7315, Val Acc=0.8252\n",
            "Epoch 8: Train Loss=0.0264, Train Acc=0.9951 | Val Loss=0.8359, Val Acc=0.8201\n",
            "Epoch 9: Train Loss=0.0218, Train Acc=0.9960 | Val Loss=0.7955, Val Acc=0.8265\n",
            "Epoch 10: Train Loss=0.0196, Train Acc=0.9958 | Val Loss=0.8419, Val Acc=0.8247\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, optimizer, criterion, DEVICE, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg7VYi4hy65e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPm0QbHTD1ATqlRlnuAUk7Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}